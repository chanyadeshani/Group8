{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the important libraries needed for Data Manipulation, classification and Analysis\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from math import isnan\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns \n",
    "from sklearn.datasets import load_digits \n",
    "digits = load_digits() \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and merging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data using predefined file path\n",
    "data_file1 = 'train.csv' \n",
    "df_train= pd.read_csv(data_file1)\n",
    "# Importing data using user defined file path\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_gender_submission = pd.read_csv('gender_submission.csv')\n",
    "\n",
    "# Merge the dataset using PassengerId as a key and using right join \n",
    "# (all the rows from df_gender_submission and only matching rows from df_test)\n",
    "result = pd.merge(df_gender_submission, df_test, how = 'right', on = ['PassengerId'])\n",
    "# Concatenating df_train and result dataframe\n",
    "train_df = pd.concat([df_train, result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check first 3 rows of the data\n",
    "train_df.head(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print first few rows and last few rows\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the result from the previous step, when using *head* method of the Dataframe class,\n",
    "it is clear that all the *object* data types are *Strings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of rows and columns\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\tData description') \n",
    "print('*****************************************') \n",
    "\n",
    "''' Within the three quatition (i.e ''' '''), it is posible to display a pragraph as it is.\n",
    "Therefore new line can be enter typing a sentence in a new line or using \\n'''\n",
    "print('''•\\tPassengerId: Id of every passenger.\\n•\\tSurvived: This feature have value 0 and 1. 0 for not survived and 1 for survived.\n",
    "•\\tPclass: There are 3 classes: Class 1, Class 2 and Class 3.\\n•\\tName: Name of passenger.\\n•\\tSex: Gender of passenger.\n",
    "•\\tAge: Age of passenger.\\n•\\tSibSp: Indication that passenger have siblings and spouse.\\n•\\tParch: Whether a passenger is alone or have family.\n",
    "•\\tTicket: Ticket number of passenger.\\n•\\tFare: Indicating the fare.\\n•\\tCabin: The cabin of passenger.\\n•\\tEmbarked: The embarked category''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring data to identify Anomalies/ Missing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the unique values count\n",
    "print('Number of unique values in each columns')\n",
    "for col in train_df.columns:\n",
    "    print(str(col)+ '   ' + str(train_df[col].nunique()))\n",
    "print(f'It is clear when look at the number of unique values, that there are {train_df.PassengerId.nunique()} unique values in the PassengerId column. However, only {train_df.PassengerId.nunique()} unique values in the Name column. This raise the suspision that there may be duplicate entry in the data set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO %%%%%%%%%%%%%% Need to write code to check and remove duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###insert this plot at the begining of the data when we still had missing values, this is a graphical presentation of the variable where there is missing data in the data set\n",
    "\n",
    "plt.subplots(figsize=(10,6)) #the figsize help zoom our plot to give a better visible view\n",
    "sns.heatmap(train_df.isnull(), cbar=False, cmap=\"YlGnBu_r\")\n",
    "\n",
    "categorical_variable = ['Survived', 'Sex', 'Pclass', 'SibSp', 'Parch', 'Embarked']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of rows missing in each column\n",
    "for column in train_df.columns:\n",
    "    percentage = train_df[column].isnull().mean()\n",
    "    print(f'{column}: {round(percentage*100,4)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Our desired number of plot row and column size'\n",
    "categorical_plot_nrows = 2\n",
    "categorical_plot_ncols = 3\n",
    "\n",
    "fig, axs = plt.subplots(categorical_plot_nrows, categorical_plot_ncols, figsize = (categorical_plot_ncols*3.5, categorical_plot_nrows*3))\n",
    "\n",
    "for r in range(0, categorical_plot_nrows):\n",
    "    for c in range(0, categorical_plot_ncols):\n",
    "        i = r*categorical_plot_ncols+c\n",
    "        ax = axs[r][c]\n",
    "        sns.countplot(train_df[categorical_variable[i]], hue=train_df[\"Survived\"], ax=ax)\n",
    "        ax.set_title(categorical_variable[i], fontsize=12, fontweight=\"bold\")\n",
    "        ax.legend(title=\"Survived\", loc='upper center')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming the column values\n",
    "### Transforming Survived and Pclass columns from integer to String\n",
    "Values are transformed form numerical values to categotical values as it is easier to understand the data in the exploratary analysis.\n",
    "Also, after the transformation, graph lables become more discriptive and easier to understand.\n",
    "\n",
    "### Renaming Embarked column values to their proper Embarcation port\n",
    "This will make data more understandable in data exploration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survived column values: maped 1 -> Survived and 0 -> Deceased\n",
    "train_df.loc[train_df['Survived'] == 0, 'Survived'] = 'Deceased' \n",
    "train_df.loc[train_df['Survived'] == 1, 'Survived'] = 'Survived' \n",
    "train_df['Survived'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pclass column values: maped 1 -> First Class, 2 -> Second Class and 3 -> Third Class\n",
    "train_df.loc[train_df['Pclass'] == 1, 'Pclass'] = 'First Class' \n",
    "train_df.loc[train_df['Pclass'] == 2, 'Pclass'] = 'Second Class' \n",
    "train_df.loc[train_df['Pclass'] == 3, 'Pclass'] = 'Third Class' \n",
    "train_df['Pclass'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embarked column values: maped C -> Cherbourg, Q -> Queenstown and S -> Southampton\n",
    "train_df.loc[train_df['Embarked'] == 'C', 'Embarked'] = 'Cherbourg' \n",
    "train_df.loc[train_df['Embarked'] == 'Q', 'Embarked'] = 'Queenstown' \n",
    "train_df.loc[train_df['Embarked'] == 'S', 'Embarked'] = 'Southampton'\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can drop PasengerId column as it does not hold valuble information for the analysis\n",
    "train_df.drop('PassengerId',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic statistics before fixing data for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The average age of passengers? \n",
    "train_df['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO%%%%%%%%%%%% WE NEED CHECH THIS @Bassey\n",
    "# Median Age and Ticket fare price of Pax\n",
    "#train_df[['Age', 'Fare']].median()\n",
    "#train_df.describe(include='all')\n",
    "\n",
    "#instead of using above predifined 'describe function' we can combined aggregating statistics \n",
    "train_df.agg( \n",
    "    { \n",
    "        'Age': ['min', 'max', 'mean', 'median', 'skew'], \n",
    "        'Fare': ['min', 'max', 'mean', 'median', 'skew'], \n",
    "    } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting by group\n",
    "train_df.groupby('Pclass')['Pclass'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Do we want all of the below code for our final report@ Bassey\n",
    "train_df.isnull()  # is any missing values in dataframe\n",
    "train_df.isnull().any()  # is any missing values across columns\n",
    "train_df.isnull().sum().sum()   # count of missing values of the entire dataframe\n",
    "count_NAN = len(train_df) - train_df.count() # count of missing values across columns\n",
    "count_NAN\n",
    "\n",
    "max_missing = 0\n",
    "for i in range(len(train_df.index)):  # count of missing values across rows\n",
    "    #print('NAN in row ', i , ' : ', train_df.iloc[i].isnull().sum())\n",
    "    missing_current_row = train_df.iloc[i].isnull().sum()\n",
    "    if(max_missing < missing_current_row):\n",
    "        max_missing = missing_current_row\n",
    "\n",
    "print('maximum null values in a row : ', max_missing, '.','\\nTherefore, dropping rows containing missing values are disadvantageous')\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting of missing values of a particular column\n",
    "train_df.Age.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of missing values of column by group\n",
    "'''count of missing values of column by group\n",
    " Because we dont havve missing values in sex all the missing values is coming from Age'''\n",
    "train_df.groupby(['Sex'])['Age'].apply(lambda x: x.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the na in age and Fare column with mean\n",
    "train_df['Age'] = train_df['Age'].fillna(round(train_df['Age'].mean()))\n",
    "train_df['Fare'] = train_df['Fare'].fillna(round(train_df['Fare'].mean()))\n",
    "\n",
    "#checking if there are any remaining missing value\n",
    "print('Number of missing values remaining in Age column is' ,train_df.Age.isnull().sum())\n",
    "print('Number of missing values remaining in Fare column is' ,train_df.Fare.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with mode of the Embarked column\n",
    "train_df['Embarked'] = train_df['Embarked'].fillna(train_df['Embarked'].mode()[0])\n",
    "print('Number of missing values remaining in Embarked column is' ,train_df.Fare.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if there is still any missing data in train dataset\n",
    "print('Missing value remaining in the dataset', train_df.isna().sum().max())\n",
    "print('Missing values of the Cabin column', train_df.Cabin.isnull().sum())\n",
    "print('IT is clear that all the remaining missing values are from Cabin column. At his point, not going to impute missing values in Cabin variable as there are more than 60% of the values are missing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "survival_labels = [\"Survived\", \"Deceased\"]\n",
    "survival_counts = [train_df.Survived.value_counts()[1], train_df.Survived.value_counts()[0]]\n",
    "sns.barplot(x= survival_labels, y = survival_counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data transformation on Age column\n",
    "# Grouping age values\n",
    "\n",
    "train_df.loc[train_df['Age'] <= 1, 'age_group'] = 'baby'\n",
    "train_df.loc[train_df['Age'].between(1,3), 'age_group'] = 'todlers'\n",
    "train_df.loc[train_df['Age'].between(4,10), 'age_group'] = 'children'\n",
    "train_df.loc[train_df['Age'].between(11,19), 'age_group'] = 'teenage'\n",
    "train_df.loc[train_df['Age'].between(20,35), 'age_group'] = 'yadult'\n",
    "train_df.loc[train_df['Age'].between(36,60), 'age_group'] = 'adult'\n",
    "train_df.loc[train_df['Age']>60, 'age_group'] = 'elder'\n",
    "\n",
    "# Age grouping to two groups Child or Adult\n",
    "train_df.loc[train_df['Age'] <= 18, 'child_adult'] = 'child'\n",
    "train_df.loc[train_df['Age'] > 18, 'child_adult'] = 'adult'\n",
    "\n",
    "# Age grouping using mean values\n",
    "train_df.loc[train_df['Age'].round() <= 10, 'mean_age'] = 5\n",
    "train_df.loc[train_df['Age'].round().between(11,20), 'mean_age'] = 15\n",
    "train_df.loc[train_df['Age'].round().between(21,30), 'mean_age'] = 25\n",
    "train_df.loc[train_df['Age'].round().between(31,40), 'mean_age'] = 35\n",
    "train_df.loc[train_df['Age'].round().between(41,50), 'mean_age'] = 45\n",
    "train_df.loc[train_df['Age'].round().between(51,60), 'mean_age'] = 55\n",
    "train_df.loc[train_df['Age'].round().between(61,70), 'mean_age'] = 65\n",
    "train_df.loc[train_df['Age'] > 70, 'mean_age'] = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Maximum of Fare: ', df_train['Fare'].max())\n",
    "print('Minimum of Fare: ', df_train['Fare'].min())\n",
    "print('Mean of the Fare: ', train_df['Fare'].mean())\n",
    "\n",
    "# Fare grouping using mean values of the range\n",
    "train_df.loc[train_df['Fare'].round() <= 100, 'binned_fare'] = 50\n",
    "train_df.loc[train_df['Fare'].round().between(101,200), 'binned_fare'] = 150\n",
    "train_df.loc[train_df['Fare'].round().between(201,300), 'binned_fare'] = 250\n",
    "train_df.loc[train_df['Fare'].round().between(301,400), 'binned_fare'] = 350\n",
    "train_df.loc[train_df['Fare'].round().between(401,500), 'binned_fare'] = 450\n",
    "train_df.loc[train_df['Fare'] > 500, 'binned_fare'] = 550"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate variance using a function\n",
    "\n",
    "def variance_calculator(df_variable):\n",
    "    sum_variable = 0\n",
    "    for value in df_variable:\n",
    "        if (isnan(value) != True):\n",
    "            sum_variable += value\n",
    "    mean = sum_variable/len(df_variable)\n",
    "\n",
    " \n",
    "    sum_of_squares = 0\n",
    "    for value in df_variable:\n",
    "        if (isnan(value) != True):\n",
    "            sum_of_squares += value **2\n",
    "    mean_squares = sum_of_squares/len(df_variable)\n",
    "\n",
    "\n",
    "    return mean_squares - mean**2\n",
    "\n",
    "# The above calculation can also be done using the method numpy.var\n",
    "# np.var(df_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Variance of Fare calculated using the defined function {round(variance_calculator(train_df.Fare),2)}')\n",
    "print(f'Variance of Fare calculated using numpy function {round(np.var(train_df.Fare),2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Family class with parent and children\n",
    "\n",
    "SibSp: number of siblings/spouse\n",
    "\n",
    "Parch: number of childre/parents\n",
    "\n",
    "With the number of siblings or spouse and the number of children or parents we can create new class called Family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pasengers who travel with family (either siblings,spouse, childre or parents)\n",
    "# Copy rows which has values for either SibSp column or Parch\n",
    "train_data_families = train_df.loc[(train_df['SibSp'] > 0) | (train_df['Parch'] > 0)][['Survived', 'Name', 'Sex','Age','Ticket','Pclass']]\n",
    "train_data_families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_last_name(x):\n",
    "    # String x will split by ',' and take the first element in the resulting list. \n",
    "    # Then any whitespaces at the front and end of the first element will be truncated and returned\n",
    "    return x.split(\",\")[0].strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_families['LastName'] = train_data_families.Name.apply(extract_last_name)\n",
    "train_data_families.to_csv('family.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Person Class\n",
    "\n",
    "Creating a Person class to store pasengers traveling with family.Using the dataset created by filtering rows with non-zero values for variables SibSp(number of siblings/spouse) and Parch(number of childre/parents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person:\n",
    "    \n",
    "    def __init__(self, survival, full_name, sex, age, ticket, last_name):\n",
    "        self.last_name = last_name\n",
    "        self.ticket = ticket\n",
    "        self.full_name = full_name\n",
    "        self.survival = survival\n",
    "        self.age = age\n",
    "        self.sex = sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to hold person objects\n",
    "list_of_pasengers = []\n",
    "'''\n",
    "This code is written by us. However, as DataFrame object alredy has a similar method, desided to use it to improve performance.\n",
    "# Create list of tuples with selected column data\n",
    "with_family_list = list(zip(train_data_families[\"Survived\"], train_data_families[\"Name\"], train_data_families[\"Sex\"],\n",
    "train_data_families[\"Age\"], train_data_families[\"Ticket\"], train_data_families[\"LastName\"]))\n",
    "\n",
    "for item in with_family_list:\n",
    "    p = Person(item[0], item[1], item[2], item[3], item[4], item[5])\n",
    "    list_of_pasengers.append(p)\n",
    "'''\n",
    "\n",
    "for row in train_data_families.itertuples():\n",
    "    p = Person(row[1], row[2], row[3], row[4], row[5], row[6])\n",
    "    list_of_pasengers.append(p)\n",
    "\n",
    "# Just a test\n",
    "print(list_of_pasengers[6].last_name)\n",
    "print(list_of_pasengers[6].full_name)\n",
    "print(list_of_pasengers[6].ticket)\n",
    "print(list_of_pasengers[6].survival)\n",
    "print(list_of_pasengers[6].sex)\n",
    "print(list_of_pasengers[6].age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list_of_pasengers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When only last names are match to group families, there can be different families with same last names.\n",
    "Therefore, a variable created with ticket number  and last name used to identify families traveling together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary to store family members\n",
    "families_dict = {}\n",
    "for p in list_of_pasengers:\n",
    "    # variable containing lastname and ticket number passed as key to the dictionary\n",
    "    key = f'{p.last_name}_{p.ticket}'\n",
    "    # If there is already an entry for a family person object will append to the family members list\n",
    "    # Otherwise new list created with the person object\n",
    "    if (key in families_dict):\n",
    "        families_dict[key].append(p)\n",
    "    else:    \n",
    "        families_dict[key] = [p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of members traveled with family is {len(families_dict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary for family who traveled as a group\n",
    "family_group_dict = {}\n",
    "# If the family has more than one member they are added to another dictionary\n",
    "for key,value in families_dict.items():\n",
    "    if len(value) > 1:\n",
    "        family_group_dict[key] = value\n",
    "\n",
    "print(f'Number of families traveled together is {len(family_group_dict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the percentage of adult males and females survived in families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_male = 0\n",
    "total_female = 0\n",
    "total_children = 0\n",
    "number_f_adult_s = 0\n",
    "number_m_adult_s = 0\n",
    "number_child_s = 0\n",
    "# Each key value pair represent a family\n",
    "# Each value in the families_dict is a list family members\n",
    "for key in family_group_dict:\n",
    "    #family_mem_list = family_group_dict[key]\n",
    "    for person in family_group_dict[key]:\n",
    "        if person.age < 18:\n",
    "            total_children += 1\n",
    "            if person.survival == 'Survived':\n",
    "                number_child_s += 1\n",
    "        else:\n",
    "            if (person.sex == \"male\"):\n",
    "                total_male += 1\n",
    "                if(person.survival == 'Survived'):\n",
    "                    number_m_adult_s += 1\n",
    "            else:\n",
    "                total_female +=1\n",
    "                if(person.survival == 'Survived'):\n",
    "                    number_f_adult_s += 1\n",
    "\n",
    "print('When a pasenger traveled as a family')\n",
    "print(\"percentage of females survived \" + str(round(100 * number_f_adult_s/total_female)) + '%')\n",
    "print(\"percentage of males survived \" + str(round(100 * number_m_adult_s/total_male)) + '%')\n",
    "print(\"percentage of children survived \" + str(round(100 * number_child_s/total_children)) + '%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Random Forest Classifier\n",
    "Reference: https://www.freecodecamp.org/news/how-to-use-the-tree-based-algorithm-for-machine-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier with variables\n",
    "- Pclass\n",
    "- Sex\n",
    "- SibSp\n",
    "- Parch\n",
    "- mean_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the dataset because some columns are transforming to numeric\n",
    "rf_df = train_df\n",
    "# Convert variables to numeric values\n",
    "rf_df['Sex'] = rf_df['Sex'].replace(['female','male'],[0,1])\n",
    "\n",
    "train_df.loc[train_df['Survived'] == 'Deceased', 'Survived'] = 0 \n",
    "train_df.loc[train_df['Survived'] == 'Survived', 'Survived'] = 1\n",
    "\n",
    "train_df.loc[train_df['Pclass'] == 'First Class', 'Pclass'] = 1\n",
    "train_df.loc[train_df['Pclass'] == 'Second Class', 'Pclass'] = 2 \n",
    "train_df.loc[train_df['Pclass'] == 'Third Class' , 'Pclass'] = 3\n",
    "\n",
    "rf_df['Survived'] = rf_df['Survived'].astype('int')\n",
    "rf_df['Pclass'] = rf_df['Pclass'].astype('int')\n",
    "rf_df['mean_age'] = rf_df['mean_age'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into input and taget variable(s)\n",
    "X = rf_df.drop([\"Survived\", 'Name', 'Age', 'Ticket', 'Fare', 'PassengerId', 'Cabin', 'Embarked', 'age_group', 'child_adult', 'binned_fare'], axis = 1)\n",
    "y = rf_df[\"Survived\"]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the dataset\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, stratify=y, test_size=0.10, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Train the model using the training sets\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictin on the test set\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Model Accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "024b0ec20e0d15234e64dcdb6e92be1c0d04982ef803d66a55eaacbdf0b91525"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('HelloWorld': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
